{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs\n",
    "import time\n",
    "import os, os.path\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from Data_Generator import data_generator\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Hyperparameters\n",
    "\n",
    "batch_size = 100\n",
    "Alpha = 0.5\n",
    "margin = Alpha\n",
    "\n",
    "# Generators\n",
    "#Testing with validation data (just the image embeddings)\n",
    "training_generator = data_generator('/work/cvma/FP/data/Train_Filelist.txt',batch_size,True).generate()\n",
    "\n",
    "#No need for positive mask in Multimodal Triplet. Anchor and Positives will be fed through data inputs.'''\n",
    "def _pairwise_distances(image_embeddings, text_embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    dot_product11 = tf.matmul(image_embeddings, tf.transpose(image_embeddings))\n",
    "    dot_product22 = tf.matmul(text_embeddings, tf.transpose(text_embeddings))\n",
    "    dot_product12 = tf.matmul(image_embeddings, tf.transpose(text_embeddings))\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm11 = tf.diag_part(dot_product11)\n",
    "    square_norm22 = tf.diag_part(dot_product22)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    distances = tf.expand_dims(square_norm11, 0) - 2.0 * dot_product12 + tf.expand_dims(square_norm22, 1)\n",
    "\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = tf.to_float(tf.equal(distances, 0.0))\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = tf.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "#No need for positive mask in Multimodal Triplet. Anchor and Positives will be fed through data inputs.\n",
    "\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check if labels[i] != labels[k]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    mask = tf.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i == j, k is distinct\n",
    "        - i == j and labels[i] != labels[k]\n",
    "\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i == j and k is distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "    i_equal_j = tf.expand_dims(indices_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    valid_indices = tf.logical_and(tf.logical_and(i_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(valid_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "#No need for triplet mask. Negative Mask, serves as triplet mask for both L_tii and L_itt.\n",
    "\n",
    "def batch_all_triplet_loss(labels, image_embeddings, text_embeddings, margin, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    We generate all the valid triplets and average the loss over the positive ones.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the pairwise distance matrix for L_itt\n",
    "    pairwise_dist = _pairwise_distances(image_embeddings, text_embeddings)\n",
    "    \n",
    "    # Get the pairwise distance matrix for L_tii\n",
    "    pairwise_dist_transpose = tf.transpose(pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, batch_size, 1)\n",
    "    #Anchor Positive Dist is same for L_tii and L_itt\n",
    "    #identity_mask = tf.eye(tf.shape(pairwise_dist))\n",
    "    #anchor_positive_dist = tf.expand_dims(tf.multiply(identity_mask,pairwise_dist), 2)\n",
    "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\n",
    "    print(tf.shape(anchor_positive_dist))\n",
    "    #assert anchor_positive_dist.shape[2] == 1, \"{}\".format(anchor_positive_dist.shape)\n",
    "    \n",
    "    # shape (batch_size, 1, batch_size)\n",
    "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1) #L_itt\n",
    "    anchor_negative_dist_transpose = tf.expand_dims(pairwise_dist_transpose, 1) #L_tii\n",
    "    #assert anchor_negative_dist.shape[1] == 1, \"{}\".format(anchor_negative_dist.shape)\n",
    "    #assert anchor_negative_dist_transpose.shape[1] == 1, \"{}\".format(anchor_negative_dist_transpose.shape)\n",
    "\n",
    "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n",
    "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "    # and the 2nd (batch_size, 1, batch_size)\n",
    "    L_itt = anchor_positive_dist - anchor_negative_dist + margin\n",
    "    L_tii = anchor_positive_dist - anchor_negative_dist_transpose + margin\n",
    "\n",
    "    # Put to zero the invalid triplets\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    mask = tf.to_float(mask)\n",
    "    L_itt = tf.multiply(mask, L_itt)\n",
    "    L_tii = tf.multiply(mask, L_tii)\n",
    "\n",
    "    # Remove negative losses (i.e. the easy triplets)\n",
    "    L_itt = tf.maximum(L_itt, 0.0)\n",
    "    L_tii = tf.maximum(L_tii, 0.0)\n",
    "    \n",
    "\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets_tii = tf.to_float(tf.greater(L_tii, 1e-16))\n",
    "    valid_triplets_itt = tf.to_float(tf.greater(L_itt, 1e-16))\n",
    "    \n",
    "    num_positive_triplets_tii = tf.reduce_sum(valid_triplets_tii)\n",
    "    num_positive_triplets_itt = tf.reduce_sum(valid_triplets_itt)\n",
    "    \n",
    "    num_valid_triplets = tf.reduce_sum(mask)\n",
    "    fraction_positive_triplets = (num_positive_triplets_tii + num_positive_triplets_itt) / (2*num_valid_triplets + 1e-16)\n",
    "\n",
    "    # Get final mean triplet loss over the positive valid triplets\n",
    "    triplet_loss = (tf.reduce_sum(L_tii) + tf.reduce_sum(L_itt)) / (num_positive_triplets_tii + num_positive_triplets_itt + 1e-16)\n",
    "    \n",
    "    return triplet_loss, num_positive_triplets_tii, num_positive_triplets_itt\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "################# tensorflow network ###################################\n",
    "\n",
    "\n",
    "def image_net(image_dict, reuse=None, is_training=True):\n",
    "    \n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):        \n",
    "        image_input= image_dict\n",
    "        image_input = tf.reshape(image_input, shape=[-1,512,512,3])\n",
    "        conv1 = tf.layers.conv2d(image_input, 32, 3, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.average_pooling2d(conv1,2,4)\n",
    "        tf.summary.histogram(\"conv1\", conv1)\n",
    "        conv2 = tf.layers.conv2d(conv1, 128, 3, activation = tf.nn.sigmoid)\n",
    "        conv2 = tf. layers.average_pooling2d(conv2,2,4)\n",
    "        tf.summary.histogram(\"conv2\", conv2)\n",
    "        conv3 = tf.layers.conv2d(conv2, 512, 3, activation = tf.nn.sigmoid)\n",
    "        conv3 = tf.layers.average_pooling2d(conv3,2,4)\n",
    "        tf.summary.histogram(\"conv3\", conv3)\n",
    "        flat = tf.contrib.layers.flatten(conv3)\n",
    "        fc1 = tf.layers.dense(flat, 512, activation=tf.nn.relu)\n",
    "        tf.summary.histogram(\"image_fc1\", fc1)\n",
    "        out = tf.layers.batch_normalization(fc1, training=is_training\n",
    "        \n",
    "    return out \n",
    "\n",
    "\n",
    "def text_net (text_dict, reuse=None, is_training=True):\n",
    "    \n",
    "    with tf.variable_scope('model', reuse=reuse):        \n",
    "        text_input = text_dict\n",
    "        fc1 = tf.layers.dense(text_input, 300, activation = tf.nn.sigmoid)\n",
    "        tf.summary.histogram(\"fc1\", fc1)\n",
    "        fc2 = tf.layers.dense(fc1, 400, activation = tf.nn.sigmoid)\n",
    "        tf.summary.histogram(\"fc2\", fc2)\n",
    "        fc3 = tf.layers.dense(fc2, 450, activation= tf.nn.sigmoid)\n",
    "        tf.summary.histogram(\"fc3\", fc3)\n",
    "        fc4 = tf.layers.dense(fc3, 512, activation = tf.nn.sigmoid)\n",
    "        tf.summary.histogram(\"fc4\", fc4)\n",
    "        out = tf.layers.batch_normalization(fc4, training=is_training)\n",
    "    return out\n",
    "\n",
    "    \n",
    "#### my chindi network\n",
    "reuse = None\n",
    "learning_rate = 0.001\n",
    "image_dict = tf.placeholder(tf.float32, shape=(batch_size,512,512,3))\n",
    "text_dict = tf.placeholder(tf.float32, shape = (batch_size,200))\n",
    "labels = tf.placeholder(tf.float32, shape=(batch_size))\n",
    "\n",
    "\n",
    "image_embeddings = image_net(image_dict, reuse, True)\n",
    "text_embeddings = text_net(text_dict, reuse, True)\n",
    "image_embedding_mean_norm = tf.reduce_mean(tf.norm(image_embeddings, axis=1))\n",
    "tf.summary.scalar(\"embedding_image_mean_norm\", image_embedding_mean_norm)\n",
    "text_embedding_mean_norm = tf.reduce_mean(tf.norm(text_embeddings, axis=1))\n",
    "tf.summary.scalar(\"embedding_text_mean_norm\", text_embedding_mean_norm)\n",
    "# my_loss,fraction = batch_all_triplet_loss(labels, image_embeddings, text_embeddings, margin, squared=False)\n",
    "my_loss, num_tii, num_itt = batch_all_triplet_loss(labels, image_embeddings, text_embeddings, margin, squared=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op')\n",
    "minimizer = optimizer.minimize(my_loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "summary = tf.summary.merge_all()                                                   \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"folder_to_save_garbage_graph_3\", sess.graph)\n",
    "    print(\"Initializing Session\")\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, \"models/run_1/model30000.ckpt\")\n",
    "    print(\"Model Restored\")\n",
    "    print(\"Init Done\")\n",
    "    global_step = 0\n",
    "    count = 30001\n",
    "    # Number of training iterations in each epoch\n",
    "    for [images, texts], labels_input in training_generator:\n",
    "        if count < 10:\n",
    "            print(\"Running Batch Number\", count)\n",
    "        #for id, l in enumerate(labels):\n",
    "        feed_dict_batch = {image_dict: images, text_dict: texts, labels: labels_input}\n",
    "        summary_str, my_embeddings, loss_val, _num_tii, _num_itt, minimized = sess.run([summary,image_embeddings,my_loss, num_tii, num_itt, minimizer], feed_dict=feed_dict_batch)\n",
    "        if count%20 == 0 or count < 10:\n",
    "            print(count, \" -- Loss Val: \", loss_val, \" -- Trip_TII: \", _num_tii, \" -- Trip_ITT: \", _num_itt)\n",
    "        if count%5000 == 0:\n",
    "            writer.add_summary(summary_str, count) ###check whether count is not repeated again or it will be overwritten\n",
    "            writer.flush()\n",
    "            save_path = saver.save(sess, \"models/run_2/model\"+str(count)+\".ckpt\")\n",
    "            print(\"Model saved in path: %s\" % save_path)\n",
    "        if count%100000 == 0:\n",
    "            break\n",
    "        count+=1\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
