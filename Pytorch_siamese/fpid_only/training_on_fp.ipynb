{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms,datasets\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import FingerPrintDataset, FingerPrintDataset_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ayush/projects/my_pytorch/data_trial/train\n",
      "/Users/ayush/projects/my_pytorch/data_trial/train\n"
     ]
    }
   ],
   "source": [
    "data_root= '/Users/ayush/projects/my_pytorch/data_trial/'\n",
    "dataset = FingerPrintDataset(data_root,transform=transforms.Compose([\n",
    "                                 transforms.ToTensor()\n",
    "                                 \n",
    "                             ]))\n",
    "dataset_rgb = FingerPrintDataset_rgb(data_root,transform=transforms.Compose([\n",
    "                                 transforms.ToTensor()\n",
    "                                 \n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ayush/projects/my_pytorch/data_trial/train\n",
      "/Users/ayush/projects/my_pytorch/data_trial/test\n",
      "/Users/ayush/projects/my_pytorch/data_trial/train\n",
      "/Users/ayush/projects/my_pytorch/data_trial/test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = FingerPrintDataset(data_root, train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor()]))\n",
    "test_dataset = FingerPrintDataset(data_root, train=False,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset_rgb = FingerPrintDataset_rgb(data_root, train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor()]))\n",
    "test_dataset_rgb = FingerPrintDataset_rgb(data_root, train=False,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,l =train_dataset_rgb[4]\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 16\n"
     ]
    }
   ],
   "source": [
    "train_classes_set=set()\n",
    "test_classes_set=set()\n",
    "for x in train_dataset:\n",
    "    train_classes_set.add(x[1])\n",
    "for x in test_dataset:\n",
    "    test_classes_set.add(x[1])\n",
    "\n",
    "train_classes = len(train_classes_set)\n",
    "test_classes = len(test_classes_set)\n",
    "train_classes_samples=2\n",
    "test_classes_samples=2\n",
    "print(train_classes,test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import EmbeddingNet, TripletNet\n",
    "from losses import TripletLoss\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from trainer import fit\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist_classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9','10','11','12','13','14','15']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "              '#bcbd22', '#17becf','#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "              '#bcbd22']\n",
    "def plot_embeddings(embeddings, targets, xlim=None, ylim=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(15):\n",
    "        inds = np.where(targets==i)[0]\n",
    "        print(inds,i)\n",
    "        plt.scatter(embeddings[inds,0], embeddings[inds,1], alpha=0.5, color=colors[i])\n",
    "    if xlim:\n",
    "        plt.xlim(xlim[0], xlim[1])\n",
    "    if ylim:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    plt.legend(mnist_classes)\n",
    "\n",
    "def extract_embeddings(dataloader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), 2))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            k += len(images)\n",
    "    return embeddings, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/projects/my_pytorch/data_generator.py:33: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/ayush/projects/my_pytorch/data_generator.py:38: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n",
      "/Users/ayush/projects/my_pytorch/data_generator.py:103: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/ayush/projects/my_pytorch/data_generator.py:108: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import BalancedBatchSampler\n",
    "\n",
    "train_batch_sampler = BalancedBatchSampler(train_dataset.train_labels, n_classes=train_classes, n_samples=train_classes_samples)\n",
    "test_batch_sampler = BalancedBatchSampler(test_dataset.test_labels, n_classes=test_classes, n_samples=train_classes_samples)\n",
    "\n",
    "train_batch_sampler_rgb = BalancedBatchSampler(train_dataset_rgb.train_labels, n_classes=train_classes, n_samples=train_classes_samples)\n",
    "test_batch_sampler_rgb = BalancedBatchSampler(test_dataset_rgb.test_labels, n_classes=test_classes, n_samples=train_classes_samples)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "online_train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_batch_sampler, **kwargs)\n",
    "online_test_loader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_batch_sampler, **kwargs)\n",
    "\n",
    "\n",
    "online_train_loader_rgb = torch.utils.data.DataLoader(train_dataset_rgb, batch_sampler=train_batch_sampler, **kwargs)\n",
    "online_test_loader_rgb = torch.utils.data.DataLoader(test_dataset_rgb, batch_sampler=test_batch_sampler, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the network and training parameters\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from networks import EmbeddingNet\n",
    "from losses import OnlineTripletLoss\n",
    "from utils import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EmbeddingNet()\n",
    "#model = embedding_net\n",
    "model=torchvision.models.squeezenet1_1(pretrained=True)\n",
    "model.classifier[1] = nn.Conv2d(512, 256, kernel_size=(1,1), stride=(1,1))\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 15\n",
    "log_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.585611\tAverage nonzero triplets: 13.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.533194\tAverage nonzero triplets: 12.5\n",
      "Epoch: 1/15. Train set: Average loss: 0.5594\tAverage nonzero triplets: 12.5\n",
      "Epoch: 1/15. Validation set: Average loss: 0.4888\tAverage nonzero triplets: 10.333333333333334\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.539685\tAverage nonzero triplets: 14.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.619927\tAverage nonzero triplets: 14.5\n",
      "model saved as ./saved_model/model_train_loss_0.5798059403896332_epoch_1\n",
      "Epoch: 2/15. Train set: Average loss: 0.5798\tAverage nonzero triplets: 14.5\n",
      "Epoch: 2/15. Validation set: Average loss: 0.5292\tAverage nonzero triplets: 10.0\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.642347\tAverage nonzero triplets: 10.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.555956\tAverage nonzero triplets: 10.5\n",
      "Epoch: 3/15. Train set: Average loss: 0.5992\tAverage nonzero triplets: 10.5\n",
      "Epoch: 3/15. Validation set: Average loss: 0.5479\tAverage nonzero triplets: 9.666666666666666\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.519400\tAverage nonzero triplets: 11.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.588895\tAverage nonzero triplets: 11.5\n",
      "model saved as ./saved_model/model_train_loss_0.5541472136974335_epoch_3\n",
      "Epoch: 4/15. Train set: Average loss: 0.5541\tAverage nonzero triplets: 11.5\n",
      "Epoch: 4/15. Validation set: Average loss: 0.6102\tAverage nonzero triplets: 10.333333333333334\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.520158\tAverage nonzero triplets: 9.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.676154\tAverage nonzero triplets: 13.0\n",
      "Epoch: 5/15. Train set: Average loss: 0.5982\tAverage nonzero triplets: 13.0\n",
      "Epoch: 5/15. Validation set: Average loss: 0.4963\tAverage nonzero triplets: 8.333333333333334\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.653484\tAverage nonzero triplets: 9.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.463779\tAverage nonzero triplets: 10.0\n",
      "model saved as ./saved_model/model_train_loss_0.5586312860250473_epoch_5\n",
      "Epoch: 6/15. Train set: Average loss: 0.5586\tAverage nonzero triplets: 10.0\n",
      "Epoch: 6/15. Validation set: Average loss: 0.4351\tAverage nonzero triplets: 9.333333333333334\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.403549\tAverage nonzero triplets: 13.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.499028\tAverage nonzero triplets: 13.0\n",
      "Epoch: 7/15. Train set: Average loss: 0.4513\tAverage nonzero triplets: 13.0\n",
      "Epoch: 7/15. Validation set: Average loss: 0.4836\tAverage nonzero triplets: 8.333333333333334\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.594425\tAverage nonzero triplets: 14.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.491304\tAverage nonzero triplets: 12.0\n",
      "model saved as ./saved_model/model_train_loss_0.542864516377449_epoch_7\n",
      "Epoch: 8/15. Train set: Average loss: 0.5429\tAverage nonzero triplets: 12.0\n",
      "Epoch: 8/15. Validation set: Average loss: 0.4421\tAverage nonzero triplets: 9.333333333333334\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.444516\tAverage nonzero triplets: 13.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.609183\tAverage nonzero triplets: 13.5\n",
      "Epoch: 9/15. Train set: Average loss: 0.5268\tAverage nonzero triplets: 13.5\n",
      "Epoch: 9/15. Validation set: Average loss: 0.4756\tAverage nonzero triplets: 7.666666666666667\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.505659\tAverage nonzero triplets: 15.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.578745\tAverage nonzero triplets: 13.0\n",
      "model saved as ./saved_model/model_train_loss_0.5422018766403198_epoch_9\n",
      "Epoch: 10/15. Train set: Average loss: 0.5422\tAverage nonzero triplets: 13.0\n",
      "Epoch: 10/15. Validation set: Average loss: 0.4682\tAverage nonzero triplets: 11.0\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.463736\tAverage nonzero triplets: 13.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.480712\tAverage nonzero triplets: 12.5\n",
      "Epoch: 11/15. Train set: Average loss: 0.4722\tAverage nonzero triplets: 12.5\n",
      "Epoch: 11/15. Validation set: Average loss: 0.4242\tAverage nonzero triplets: 11.0\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.429803\tAverage nonzero triplets: 12.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.447823\tAverage nonzero triplets: 12.0\n",
      "model saved as ./saved_model/model_train_loss_0.43881291151046753_epoch_11\n",
      "Epoch: 12/15. Train set: Average loss: 0.4388\tAverage nonzero triplets: 12.0\n",
      "Epoch: 12/15. Validation set: Average loss: 0.4927\tAverage nonzero triplets: 10.666666666666666\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.374295\tAverage nonzero triplets: 13.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.327014\tAverage nonzero triplets: 12.0\n",
      "Epoch: 13/15. Train set: Average loss: 0.3507\tAverage nonzero triplets: 12.0\n",
      "Epoch: 13/15. Validation set: Average loss: 0.4941\tAverage nonzero triplets: 9.0\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.388369\tAverage nonzero triplets: 11.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.459927\tAverage nonzero triplets: 14.5\n",
      "model saved as ./saved_model/model_train_loss_0.42414771020412445_epoch_13\n",
      "Epoch: 14/15. Train set: Average loss: 0.4241\tAverage nonzero triplets: 14.5\n",
      "Epoch: 14/15. Validation set: Average loss: 0.4028\tAverage nonzero triplets: 9.666666666666666\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.582396\tAverage nonzero triplets: 14.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.388730\tAverage nonzero triplets: 14.5\n",
      "model saved as ./saved_model/model_train_loss_0.485563188791275_epoch_14\n",
      "Epoch: 15/15. Train set: Average loss: 0.4856\tAverage nonzero triplets: 14.5\n",
      "Epoch: 15/15. Validation set: Average loss: 0.5954\tAverage nonzero triplets: 7.333333333333333\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.553368\tAverage nonzero triplets: 12.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.403903\tAverage nonzero triplets: 12.0\n",
      "Epoch: 1/15. Train set: Average loss: 0.4786\tAverage nonzero triplets: 12.0\n",
      "Epoch: 1/15. Validation set: Average loss: 0.5115\tAverage nonzero triplets: 8.666666666666666\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.395964\tAverage nonzero triplets: 16.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.430512\tAverage nonzero triplets: 12.5\n",
      "model saved as ./saved_model/model_train_loss_0.41323816776275635_epoch_1\n",
      "Epoch: 2/15. Train set: Average loss: 0.4132\tAverage nonzero triplets: 12.5\n",
      "Epoch: 2/15. Validation set: Average loss: 0.4986\tAverage nonzero triplets: 10.0\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.442925\tAverage nonzero triplets: 10.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [3/113 (50%)]\tLoss: 0.523496\tAverage nonzero triplets: 11.0\n",
      "Epoch: 3/15. Train set: Average loss: 0.4832\tAverage nonzero triplets: 11.0\n",
      "Epoch: 3/15. Validation set: Average loss: 0.4822\tAverage nonzero triplets: 8.666666666666666\n",
      "0 torch.Size([44, 3, 512, 512]) torch.Size([44])\n",
      "Train: [0/113 (0%)]\tLoss: 0.401774\tAverage nonzero triplets: 14.0\n",
      "1 torch.Size([44, 3, 512, 512]) torch.Size([44])\n"
     ]
    }
   ],
   "source": [
    "#fit(online_train_loader, online_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[AverageNonzeroTripletsMetric()])\n",
    "\n",
    "##############################################################################################\n",
    "optimizer=torch.optim.AdamW(model.classifier.parameters())\n",
    "fit(online_train_loader_rgb, online_test_loader_rgb, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[AverageNonzeroTripletsMetric()])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=0.00001)\n",
    "fit(online_train_loader_rgb, online_test_loader_rgb, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[AverageNonzeroTripletsMetric()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 1 and 3 in dimension 1 at /Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/TH/generic/THTensor.cpp:689",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f98578cde41e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monline_train_loader_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 1 and 3 in dimension 1 at /Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/TH/generic/THTensor.cpp:689"
     ]
    }
   ],
   "source": [
    "for a,b in enumerate(online_train_loader_rgb):\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\ntrain_embeddings_otl, train_labels_otl = extract_embeddings(online_train_loader, model)\\nplot_embeddings(train_embeddings_otl, train_labels_otl)\\nval_embeddings_otl, val_labels_otl = extract_embeddings(online_test_loader, model)\\nplot_embeddings(val_embeddings_otl, val_labels_otl)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "train_embeddings_otl, train_labels_otl = extract_embeddings(online_train_loader, model)\n",
    "plot_embeddings(train_embeddings_otl, train_labels_otl)\n",
    "val_embeddings_otl, val_labels_otl = extract_embeddings(online_test_loader, model)\n",
    "plot_embeddings(val_embeddings_otl, val_labels_otl)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import final_test_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=final_test_epoch('/Users/ayush/projects/my_pytorch/probe' ,'/Users/ayush/projects/my_pytorch/gallery',model,metrics=[AverageNonzeroTripletsMetric()],transform=transforms.Compose([\n",
    "                                 transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
