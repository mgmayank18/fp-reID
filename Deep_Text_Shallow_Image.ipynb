{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import libs\n",
    "import time\n",
    "import os, os.path\n",
    "import random\n",
    "import cv2\n",
    "import keras\n",
    "import matplotlib\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, Concatenate, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "#Hyperparameters\n",
    "\n",
    "BatchSize = 64\n",
    "Alpha = 0.5\n",
    "\n",
    "#Read Data Paths\n",
    "\n",
    "images = sorted(glob.glob('/local/manasa/FP/data/*/*[!_xyt]/*'))\n",
    "xyt = sorted(glob.glob('/local/manasa/FP/data/*/*_xyt/*'))\n",
    "image_xyt_pairs = [list(a) for a in zip(images,xyt)]\n",
    "\n",
    "#Image Data Preprocessing\n",
    "\n",
    "label_dict = {}\n",
    "label_counter = 0\n",
    "labels = []\n",
    "image_list = []\n",
    "text_list = []\n",
    "\n",
    "#Minutae Data Preprocessing\n",
    "def crop_top(df,crop_size):\n",
    "    #this will take top n inputs for df\n",
    "    if df.shape[0]<crop_size:\n",
    "        d_zero = np.zeros((crop_size,df.shape[1]), dtype=int)\n",
    "        d_zero[:df.shape[0], :df.shape[1]]=df\n",
    "        return d_zero\n",
    "    else:\n",
    "        return df[0:crop_size,:]\n",
    "    \n",
    "def is_file_empty(filename):\n",
    "    return os.stat(filename).st_size == 0\n",
    "\n",
    "def preprocess_xyt_file(filename, crop_size=50):\n",
    "    df=np.loadtxt(filename, delimiter=' ')\n",
    "    if len(np.shape(df)) != 1:\n",
    "        df = df[df[:,3].argsort()[::-1]]\n",
    "    else:\n",
    "        df = np.expand_dims(df,0)\n",
    "    normalization_factor = np.array([512.0,512.0,360.0,100.0])\n",
    "    df_new = crop_top(df,crop_size)/normalization_factor\n",
    "    return df_new.flatten()\n",
    "\n",
    "def assign_label(key):\n",
    "    global label_counter\n",
    "    if key in label_dict.keys():\n",
    "        labels.append(label_dict[key])\n",
    "        return 0\n",
    "    else:\n",
    "        label_dict[key] = label_counter\n",
    "        labels.append(label_counter)\n",
    "        label_counter=label_counter+1\n",
    "        #Do Something\n",
    "        return 0\n",
    "    \n",
    "for image in images:\n",
    "    filename = image.split(\"/\")[-1]\n",
    "    foldername = \"/\".join(image.split(\"/\")[0:-1])\n",
    "    tags = filename.split(\"_\")\n",
    "    if len(tags) == 5:\n",
    "        key = foldername+\"/\"+\"_\".join(tags[0:4])\n",
    "        assign_label(key)\n",
    "        image_data = cv2.imread(image)\n",
    "        image_list.append(image_data)\n",
    "        Index = images.index(image)\n",
    "        text_list.append(preprocess_xyt_file(xyt[Index]))\n",
    "\n",
    "    elif len(tags) == 3:\n",
    "        key = foldername+\"/\"+tags[0]+\"_\"+tags[2]\n",
    "        assign_label(key)\n",
    "        image_data = cv2.imread(image)\n",
    "        image_list.append(image_data)\n",
    "        Index = images.index(image)\n",
    "        text_list.append(preprocess_xyt_file(xyt[Index]))\n",
    "    elif len(tags) == 4:\n",
    "\tIndex = images.index(image)\n",
    "\tif is_file_empty(xyt[Index]):\n",
    "\t\tcontinue\n",
    "\tkey = foldername+\"/\"+tags[0]+\"_sess_\"+tags[2]+\"_\"+tags[3]\n",
    "        assign_label(key)\n",
    "\timage_list.append(image_data)\n",
    "        text_list.append(preprocess_xyt_file(xyt[Index]))\n",
    "    elif len(tags) == 2:\n",
    "\tkey = foldername+tags[0][1:]\n",
    "\tassign_label(key)\n",
    "\timage_list.append(image_data)\n",
    "        Index = images.index(image)\n",
    "        text_list.append(preprocess_xyt_file(xyt[Index])) \n",
    "        \n",
    "print(\"Image List: \", len(image_list), \"Text List : \", len(text_list), \"Labels : \", len(labels))\n",
    "\n",
    "\"\"\"Define functions to create the triplet loss with online triplet mining.\"\"\"\n",
    "\n",
    "ses = tf.Session()\n",
    "\n",
    "image_embeddings = tf.random_uniform([1000,512], minval=0, maxval=1, dtype=tf.float32)\n",
    "image_embeddings = tf.constant([[1.0,1.0,1.0],[3.0,3.0,3.0]])\n",
    "text_embeddings = tf.random_uniform([1000,512], minval=0, maxval=1, dtype=tf.float32)\n",
    "text_embeddings = tf.constant([[1.0,2.0,1.0],[1.0,2.0,3.0]])\n",
    "y_pred = tf.concat([image_embeddings, text_embeddings], 0)\n",
    "\n",
    "y1,y2 =tf.split(y_pred, num_or_size_splits=2, axis=0)\n",
    "tf.shape(image_embeddings)\n",
    "\n",
    "#No need for positive mask in Multimodal Triplet. Anchor and Positives will be fed through data inputs.'''\n",
    "def _pairwise_distances(image_embeddings, text_embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    dot_product11 = tf.matmul(image_embeddings, tf.transpose(image_embeddings))\n",
    "    dot_product22 = tf.matmul(text_embeddings, tf.transpose(text_embeddings))\n",
    "    dot_product12 = tf.matmul(image_embeddings, tf.transpose(text_embeddings))\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm11 = tf.diag_part(dot_product11)\n",
    "    square_norm22 = tf.diag_part(dot_product22)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    distances = tf.expand_dims(square_norm11, 0) - 2.0 * dot_product12 + tf.expand_dims(square_norm22, 1)\n",
    "\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = tf.to_float(tf.equal(distances, 0.0))\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = tf.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check if labels[i] != labels[k]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    mask = tf.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i == j, k is distinct\n",
    "        - i == j and labels[i] != labels[k]\n",
    "\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i == j and k is distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "    i_equal_j = tf.expand_dims(indices_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    valid_indices = tf.logical_and(tf.logical_and(i_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(valid_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "#No need for triplet mask. Negative Mask, serves as triplet mask for both L_tii and L_itt.\n",
    "\n",
    "def batch_all_triplet_loss(labels, image_embeddings, text_embeddings, margin, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    We generate all the valid triplets and average the loss over the positive ones.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the pairwise distance matrix for L_itt\n",
    "    pairwise_dist = _pairwise_distances(image_embeddings, text_embeddings)\n",
    "    \n",
    "    # Get the pairwise distance matrix for L_tii\n",
    "    pairwise_dist_transpose = tf.transpose(pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, batch_size, 1)\n",
    "    #Anchor Positive Dist is same for L_tii and L_itt\n",
    "    #identity_mask = tf.eye(tf.shape(pairwise_dist))\n",
    "    #anchor_positive_dist = tf.expand_dims(tf.multiply(identity_mask,pairwise_dist), 2)\n",
    "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\n",
    "    print(tf.shape(anchor_positive_dist))\n",
    "    #assert anchor_positive_dist.shape[2] == 1, \"{}\".format(anchor_positive_dist.shape)\n",
    "    \n",
    "    # shape (batch_size, 1, batch_size)\n",
    "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1) #L_itt\n",
    "    anchor_negative_dist_transpose = tf.expand_dims(pairwise_dist_transpose, 1) #L_tii\n",
    "    #assert anchor_negative_dist.shape[1] == 1, \"{}\".format(anchor_negative_dist.shape)\n",
    "    #assert anchor_negative_dist_transpose.shape[1] == 1, \"{}\".format(anchor_negative_dist_transpose.shape)\n",
    "\n",
    "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n",
    "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "    # and the 2nd (batch_size, 1, batch_size)\n",
    "    L_itt = anchor_positive_dist - anchor_negative_dist + margin\n",
    "    L_tii = anchor_positive_dist - anchor_negative_dist_transpose + margin\n",
    "\n",
    "    # Put to zero the invalid triplets\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    mask = tf.to_float(mask)\n",
    "    L_itt = tf.multiply(mask, L_itt)\n",
    "    L_tii = tf.multiply(mask, L_tii)\n",
    "\n",
    "    # Remove negative losses (i.e. the easy triplets)\n",
    "    L_itt = tf.maximum(L_itt, 0.0)\n",
    "    L_tii = tf.maximum(L_tii, 0.0)\n",
    "    \n",
    "\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets_tii = tf.to_float(tf.greater(L_tii, 1e-16))\n",
    "    valid_triplets_itt = tf.to_float(tf.greater(L_itt, 1e-16))\n",
    "    \n",
    "    num_positive_triplets_tii = tf.reduce_sum(valid_triplets_tii)\n",
    "    num_positive_triplets_itt = tf.reduce_sum(valid_triplets_itt)\n",
    "    \n",
    "    num_valid_triplets = tf.reduce_sum(mask)\n",
    "    fraction_positive_triplets = (num_positive_triplets_tii + num_positive_triplets_itt) / (2*num_valid_triplets + 1e-16)\n",
    "\n",
    "    # Get final mean triplet loss over the positive valid triplets\n",
    "    triplet_loss = (tf.reduce_sum(L_tii) + tf.reduce_sum(L_itt)) / (num_positive_triplets_tii + num_positive_triplets_itt + 1e-16)\n",
    "    \n",
    "    return triplet_loss\n",
    "\n",
    "\n",
    "def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
    "    mask_anchor_positive = tf.to_float(mask_anchor_positive)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "    tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
    "    mask_anchor_negative = tf.to_float(mask_anchor_negative)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "    tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image_net consists of 3 conv layers \n",
    "\n",
    "def image_net(image_dict, reuse, is_training):\n",
    "    \n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        \n",
    "        image_input= image_dict\n",
    "        image_input = tf.reshape(image_input, shape=[-1,512,512,3])\n",
    "        conv1 = tf.layers.conv2d(image_input, 32, 3, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.average_pooling2d(conv1,2,2)\n",
    "        conv2 = tf.layers.conv2d(conv1, 128, 3, activation = tf.nn.sigmoid)\n",
    "        conv2 = tf. layers.average_pooling2d(conv2,2,2)\n",
    "        conv3 = tf.layers.conv2d(conv2, 512, 3, activation = tf.nn.sigmoid)\n",
    "        conv3 = tf.layers.average_pooling2d(conv3,2,2)\n",
    "        fc1 = tf.contrib.layers.flatten(conv3)\n",
    "        out = tf.layers.batch_normalization(fc1, momentum=bn_momentum, training=is_training)\n",
    "        \n",
    "    return out \n",
    "\n",
    "# The text_net consists of 4 fc layers of outputs 400, 512, 1024, 512 respectively\n",
    "\n",
    "def text_net (text_dict, reuse, is_training):\n",
    "    \n",
    "    with tf.variable_scope('model', reuse=reuse):\n",
    "        \n",
    "        text_input = text_dict\n",
    "        fc1 = tf.layers.dense(text_input,400, activation = tf.nn.sigmoid)\n",
    "        fc2 = tf.layers.dense(fc1, 512, activation = tf.nn.sigmoid)\n",
    "        fc3 = tf.layers.dense(fc2, 1024, activation= tf.nn.sigmoid)\n",
    "        fc4 = tf.layers.dense(fc3, 512, activation = tf.nn.sigmoid)\n",
    "        out = tf.layers.batch_normalization(fc4, momentum=bn_momentum, training=is_training)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train the entire model\n",
    "\n",
    "#### my chindi network\n",
    "\n",
    "image_dict = tf.placeholder(tf.float32, shape=(batch_size,512,512,3))\n",
    "text_dict = tf.placeholder(tf.float32, shape = (batch_size,200))\n",
    "labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "image_embeddings = image_net(image_dict, reuse, 1)\n",
    "text_embeddings = text_net(text_dict, reuse, 1)\n",
    "image_embedding_mean_norm = tf.reduce_mean(tf.norm(image_embeddings, axis=1))\n",
    "tf.summary.scalar(\"embedding_image_mean_norm\", image_embedding_mean_norm)\n",
    "text_embedding_mean_norm = tf.reduce_mean(tf.norm(text_embeddings, axis=1))\n",
    "tf.summary.scalar(\"embedding_text_mean_norm\", text_embedding_mean_norm)\n",
    "my_loss,fraction = batch_all_triplet_loss(labels, image_embeddings, text_embeddings, margin, squared=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(my_loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    global_step = 0\n",
    "    # Number of training iterations in each epoch\n",
    "    for images, texts, labels in generator():\n",
    "        feed_dict_batch = {image_dict: images, text_dict: texts, labels: labels}\n",
    "        sess.run(optimizer, feed_dict=feed_dict_batch)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image List:  0 Text List :  0 Labels :  0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
